# Ifeanyi-s-Data-Projects
These are some personal projects I've undertaken in the purpose of enhancing/showcasing my data science skills and analytical processes. Enjoy :)
---
Bellabeat Leaf Bracelet Case Study
---

## Introduction and background
In this case study, I will perform data analysis for Bellabeat, a high-tech manufacturer of health-focused products for women. I was tasked to analyze smart device data to gain insight into how consumers use their smart devices and provide insights on how to improve the features offered on their devices. 

### Area of focus
I chose to focus on the Leaf bracelet, which is jewlery that doubles as a wellness tracker that collects information such as: fitness activity, sleep habits, and menstrual cycles. 

### Data integrity
The data presented was generated by respondents (on a Fitbit) to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016. Eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring. Variation between output represents use of different types of Fitbit trackers and individual tracking behaviors / preferences. This dataset was pulled from [Kaggle](https://www.kaggle.com/arashnic/fitbit) and was made available through Mobius.

The original data source can be found [here](https://zenodo.org/record/53894#.Y7nl-XbMK01).The metadata confirms it is open-source. The owner has dedicated the work to the public domain by waiving all of his or her rights to the work worldwide under copyright law, including all related and neighboring rights, to the extent allowed by law. The data can be copied, modified, distributed without asking permission.

## Dataset
There are 18 different CSV files included in the dataset. 

## Loading common packages and data landscape
Loading tidyverse and other relevant packages into R for analysis. 

```{r}
install.packages(c("tidyverse", "readr", "lubridate", "skimr"))
library("lubridate")
library("tidyverse")
library("readr")
library("skimr")
```
## Loading/Viewing CSV files
First we'll use the getwd function along with the setwd function to find and set a file path. 

```{r}
getwd()
setwd("C:/Users/iofun/Downloads/Fitabase Data 4.12.16-5.12.16")
```
Next, we created two dataframes named 'fb_hourly_int' and 'fb_daily_activity' respectively and read in the CSV files from the dataset. 

```{r}
fb_daily_activity <- read_csv("dailyActivity_merged.csv")
fb_hourly_int <- read.csv("hourlyIntensities_merged.csv")
```
## Checking and cleaning data
Then we use the glimpse function to gather the characteristics of the data points which we'll then break down further for analysis.

```{r}
glimpse(fb_hourly_int)
glimpse(fb_daily_activity)
```
The glimpse function prompts us to update the data type for the date/datetime column for both data frames.

```{r}

fb_hourly_int %>%
group_by("ActivityHour") %>%	
mutate(ActivityHour = as.POSIXct(ActivityHour, tz = sys.timezone(), format = "%m/%d/%Y %H:%M"))
fb_daily_activity %>%
group_by("Id") %>%
mutate(ActivityDate=as.Date(ActivityDate, format = "%m/%d/%Y"))

```

The skimr package lends the n_unique fuction which tell us how many unique identifiers are in the dataset while the distinct and drop_na fuctions will remove any duplicates and missing data fields.

```{r}
n_unique(fb_daily_activity$Id)
n_unique(fb_hourly_int$Id)
fb_daily_activity <- fb_daily_activity %>%
  distinct() %>%
  drop_na()
fb_hourly_int <- fb_hourly_int %>%
  distinct() %>%
  drop_na()
```

## Analyze and Visualize Data
```{r}
cals <- fb_daily_activity[['Calories]]%>%
cals <- cals[cals != 0]
avg_cal <- mean(Cals)
std <- sd(cals)
y <- dnorm(cals, avg, std)
```
#plotting normal distribution curve
```{r}
plot(cals,y, type ="l", title = "Sample distribution for Calories burned", )
We'll create another dataframe for the sleep data. 
```{r}
sleep_day <- read.csv("sleepDay_merged.csv")
```

## Exploring a few key tables

Take a look at the daily_activity data.
```{r}
head(daily_activity)
```

Identify all the columsn in the daily_activity data.
```{r}
colnames(daily_activity)
```

Take a look at the sleep_day data.
```{r}
head(sleep_day)
```

Identify all the columsn in the daily_activity data.
```{r}
colnames(sleep_day)
```

Note that both datasets have the 'Id' field - this can be used to merge the datasets.

## Understanding some summary statistics
How many unique participants are there in each dataframe? It looks like there may be more participants in the daily activity dataset than the sleep dataset.

```{r distinct users}
n_distinct(daily_activity$Id)
n_distinct(sleep_day$Id)
```

How many observations are there in each dataframe?
```{r observations}
nrow(daily_activity)
nrow(sleep_day)
```

What are some quick summary statistics we'd want to know about each data frame?

For the daily activity dataframe:
```{r}
daily_activity %>%  
  select(TotalSteps,
         TotalDistance,
         SedentaryMinutes) %>%
  summary()
```

For the sleep dataframe:
```{r}
sleep_day %>%  
  select(TotalSleepRecords,
  TotalMinutesAsleep,
  TotalTimeInBed) %>%
  summary()
```

What does this tell us about how this sample of people's activities? 

## Plotting a few explorations

What's the relationship between steps taken in a day and sedentary minutes? How could this help inform the customer segments that we can market to? E.g. position this more as a way to get started in walking more? Or to measure steps that you're already taking?

```{r}
ggplot(data=daily_activity, aes(x=TotalSteps, y=SedentaryMinutes)) + geom_point()
```

What's the relationship between minutes asleep and time in bed? You might expect it to be almost completely linear - are there any unexpected trends?

```{r}
ggplot(data=sleep_day, aes(x=TotalMinutesAsleep, y=TotalTimeInBed)) + geom_point()
```

What could these trends tell you about how to help market this product? Or areas where you might want to explore further?

## Merging these two datasets together

```{r}
combined_data <- merge(sleep_day, daily_activity, by="Id")
```

Take a look at how many participants are in this data set.

```{r}
n_distinct(combined_data$Id)
```

Note that there were more participant Ids in the daily activity dataset that have been filtered out using merge. Consider using 'outer_join' to keep those in the dataset. 

Now you can explore some different relationships between activity and sleep as well. For example, do you think participants who sleep more also take more steps or fewer steps per day? Is there a relationship at all? How could these answers help inform the marketing strategy of how you position this new product?

